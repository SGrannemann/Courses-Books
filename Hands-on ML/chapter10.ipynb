{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # iris setosa?\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# equivalent way by passing all layers during creation\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation='relu'), \n",
    "keras.layers.Dense(100, activation='relu'), \n",
    "keras.layers.Dense(10, activation='softmax')])\n",
    "#keras.utils.plot_model(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) #sparse categorical because we have sparse labels (only the index of the class, rather than a one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7231 - accuracy: 0.7668 - val_loss: 0.4954 - val_accuracy: 0.8410\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4853 - accuracy: 0.8309 - val_loss: 0.4847 - val_accuracy: 0.8254\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4382 - accuracy: 0.8456 - val_loss: 0.4073 - val_accuracy: 0.8644\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4108 - accuracy: 0.8560 - val_loss: 0.4060 - val_accuracy: 0.8564\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3894 - accuracy: 0.8625 - val_loss: 0.3756 - val_accuracy: 0.8720\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3736 - accuracy: 0.8686 - val_loss: 0.3677 - val_accuracy: 0.8758\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3608 - accuracy: 0.8729 - val_loss: 0.3555 - val_accuracy: 0.8796\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3492 - accuracy: 0.8773 - val_loss: 0.3690 - val_accuracy: 0.8706\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3384 - accuracy: 0.8797 - val_loss: 0.3477 - val_accuracy: 0.8772\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3300 - accuracy: 0.8831 - val_loss: 0.3376 - val_accuracy: 0.8828\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3205 - accuracy: 0.8857 - val_loss: 0.3310 - val_accuracy: 0.8810\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3133 - accuracy: 0.8898 - val_loss: 0.3412 - val_accuracy: 0.8820\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3058 - accuracy: 0.8915 - val_loss: 0.3171 - val_accuracy: 0.8850\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2991 - accuracy: 0.8927 - val_loss: 0.3302 - val_accuracy: 0.8852\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2926 - accuracy: 0.8960 - val_loss: 0.3198 - val_accuracy: 0.8872\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2869 - accuracy: 0.8981 - val_loss: 0.3086 - val_accuracy: 0.8920\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2800 - accuracy: 0.8997 - val_loss: 0.3209 - val_accuracy: 0.8876\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2761 - accuracy: 0.9014 - val_loss: 0.3359 - val_accuracy: 0.8772\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2701 - accuracy: 0.9042 - val_loss: 0.3099 - val_accuracy: 0.8918\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2660 - accuracy: 0.9049 - val_loss: 0.3384 - val_accuracy: 0.8826\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2604 - accuracy: 0.9060 - val_loss: 0.3039 - val_accuracy: 0.8914\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2562 - accuracy: 0.9086 - val_loss: 0.3145 - val_accuracy: 0.8910\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2515 - accuracy: 0.9091 - val_loss: 0.3046 - val_accuracy: 0.8880\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2476 - accuracy: 0.9115 - val_loss: 0.2965 - val_accuracy: 0.8952\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2426 - accuracy: 0.9131 - val_loss: 0.3101 - val_accuracy: 0.8940\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2392 - accuracy: 0.9153 - val_loss: 0.2991 - val_accuracy: 0.8918\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2349 - accuracy: 0.9166 - val_loss: 0.2938 - val_accuracy: 0.8948\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2314 - accuracy: 0.9182 - val_loss: 0.2903 - val_accuracy: 0.8962\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2277 - accuracy: 0.9180 - val_loss: 0.2946 - val_accuracy: 0.8928\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2246 - accuracy: 0.9200 - val_loss: 0.2904 - val_accuracy: 0.8980\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32755041122436523, 0.885699987411499]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try out some predictions\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=-1)\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7927 - val_loss: 3.9316\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8018 - val_loss: 0.5325\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4645 - val_loss: 0.5038\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4581\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4474\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.4402\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4380\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4195\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4153\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4186\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.4093\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4037\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4004\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3966\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.4001\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4020\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3914\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3919\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3896\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4714\n",
      "162/162 [==============================] - 0s 946us/step - loss: 0.4011\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkfElEQVR4nO3deXhc9X3v8fd3Nu2y5E0YWzLGNgazChs7IcTYCZcYmkKS0lxIoKFp4qaJ2/S2TS8tfdI8NO0tTWmbBpKGEJouCQ6hTXATUkjACiEpu81mvMgGvGLZliVbu2bmd/84R9JIHkkjaUYanfm8nmees/1m5quj0WeOfmcz5xwiIjL9haa6ABERyQ4FuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBMSogW5m95tZk5m9OsxyM7N/NLNGM3vZzC7NfpkiIjKaTLbQvwWsH2H5NcBS/7EB+NrEyxIRkbEaNdCdc08CzSM0uR74V+d5Gqgys3nZKlBERDITycJrzAf2p0wf8OcdHtrQzDbgbcVTUlKyora2dlxvmEwmCYXG1v1f3HWEcKKL9rKF43rPsRhPfZNJ9U1MvtcH+V+j6hu/Xbt2HXPOzUm70Dk36gM4C3h1mGU/BK5ImX4cWDnaa65YscKN15YtW8b+pO9/2rm7lo/7PcdiXPVNItU3Mflen3P5X6PqGz/geTdMrmbjK+ggkLqpvcCfl1/CEUj0THUVIiI5k41A3wz8hn+0yzuAVufcad0tUy4cg2TvVFchIpIzo/ahm9kDwFpgtpkdAP4ciAI45/4JeAS4FmgEOoDfzFWxExKKQkKBLiLBNWqgO+duGmW5Az6TtYpyJaxAF5Fgy8/duLkQjqoPXUQCrYACPQY4SCamuhIRkZwonEAP+b1L2koXkYAqnEAPx7yh+tFFJKAU6CIiAVFAga4uFxEJtgIKdH8LXScXiUhAFU6gh6LeUF0uIhJQhRPoYQW6iARbAQa6+tBFJJgKKNDVhy4iwVY4gd5/YpECXUSCqXACXcehi0jAFVCgqw9dRIKt8AI9GZ/aOkREcqSAAr2vy0Vb6CISTIUT6CF1uYhIsBVOoPf3oavLRUSCqQADXVvoIhJMBRToOrFIRIKtcAJdF+cSkYArnEDXxblEJOAKMNDVhy4iwVRAgd7Xh66jXEQkmAon0ENhwLSFLiKBVTiBDt5WuvrQRSSgFOgiIgFRYIEeUZeLiARWgQV6TCcWiUhgFVagh6LqchGRwCqsQA8r0EUkuAow0NWHLiLBVGCBHtOJRSISWIUV6CEd5SIiwVVYga7j0EUkwDIKdDNbb2Y7zazRzG5Ls7zOzLaY2VYze9nMrs1+qVmgQBeRABs10M0sDNwDXAMsB24ys+VDmv0Z8KBzrh64EfhqtgudKOccPYRo7+zk1YOtU12OiEjWRTJoswpodM7tBTCzTcD1wPaUNg6o9MdnAIeyWWQmnHMca+vhYEsnB050cODEwPDgiU4OnOjkHk4yy07yoXt+wdN/8l7mVBRNdpkiIjljzrmRG5jdAKx3zn3Cn74FWO2c25jSZh7wGFANlAFXOedeSPNaG4ANADU1NSs2bdo05oKbOpJsP9JBm4txvNNxrNNxrDPJ8U5HT3Jw27IozC4JMbvEmF1sfPbkl6iKN3H5qf/H79UXcWlNJt9nY9fW1kZ5eXlOXjsbVN/E5Ht9kP81qr7xW7du3QvOuZXplmUr0W4CvuWcu8vM3gn8m5ld4JwbFLHOuXuBewFWrlzp1q5dO+Y3+vrP9vCtnTuAXqpLoyyoLuOSM0pYUF3C/KoSFlSXsmCmN15RHB385Ae/Q7KplWiH0TtjAWvXnju+n3YUDQ0NjOdnmyyqb2LyvT7I/xpVX25kEugHgdqU6QX+vFS/BawHcM79j5kVA7OBpmwUmeqD9fMpP/kWH7h6DWVFY/w+CkcJJXpZPq+SrftOZLs0EZEplclRLs8BS81skZnF8HZ6bh7SZh/wXgAzOw8oBo5ms9A+cyuLmV8RGnuYQ/+JRZfUVvHygVbiieTozxERmSZGDXTnXBzYCDwKvI53NMtrZnaHmV3nN/tD4JNm9hLwAHCrG61zfir4JxbV11XT0ZNg15G2qa5IRCRrMtrMdc49AjwyZN7nU8a3A+/Kbmk54B+HXl9XBcDW/SdYfmblyM8REZkmCuxMUe9qi3UzS5lZFmPrvpaprkhEJGsKL9CTvZgZ9bVVbNvfMtUViYhkTYEFeqz/4lz1dVU0NrXR2qlLAYhIMBRWoIei4JKQTFBfVw3AS9pKF5GAKKxAD/snGiV6uWjBDMxQP7qIBEaBBnoPFcVRzplbwdb9OsFIRIKhwAI95g39uxbV11WxdV8L+XjIvIjIWBVWoIf8w+79HaOX1FbR2tnLG8fap7AoEZHsKKxA79tC929y0bdjVP3oIhIEBRboA33oAEvmllNeFFE/uogEQmEGut+HHg4ZF9fO0Ba6iARCYQV6aPAWOkB9bTU73j5FR098iooSEcmOwgr0IX3o4B3pkkg6Xjmg+4yKyPRWYIE+cGJRn0tqqwB0XRcRmfYKNNAHulxmlRexcFap+tFFZNorsEDvO7Fo8AW56mureHHfCZ1gJCLTWmEFeuj0LhfwjkdvOtXN4dauKShKRCQ7CivQ0/ShAwN3MFK3i4hMYwUa6D2DZp97RiWxSIit+3SCkYhMXwUW6IMvztUnFglx4fwZbNWRLiIyjRVWoA+5OFeq+toqXjnYSk88OclFiYhkR2EFepoTi/rU11XTE0/y+uGTk1yUiEh2FFigp98pCqk7RtWPLiLTU2EGevL0QJ83o5iayiL1o4vItFVggd7X5XJ6H7qZUV9brUMXRWTaKqxAH+bEoj71dVXsa+7geFv3JBYlIpIdBRboYcBGCHTvDka6UJeITEeFFehmXj96mi4XgAvnzyAcMnW7iMi0VFiBDl4/ejL9zSxKYmHOm1ehW9KJyLRUeIEeigy7hQ7e9dFf2t9KIqkrL4rI9FJ4gR6ODduHDt4t6dq64zQ2tU1iUSIiE1eAgR4dOdB1gpGITFOFGehpTizqs2h2GTNKotoxKiLTTgEGemzEPnQzo76uSjtGRWTaySjQzWy9me00s0Yzu22YNh82s+1m9pqZfSe7ZWZRaOQuF/D60Xc3tXGya+R2IiL5ZNRAN7MwcA9wDbAcuMnMlg9psxT4E+Bdzrnzgd/PfqlZMkofOnj96M7By/tbJ6koEZGJy2QLfRXQ6Jzb65zrATYB1w9p80ngHufcCQDnXFN2y8yiEU4s6nNxbRUA29TtIiLTiI12p3szuwFY75z7hD99C7DaObcxpc0PgF3Au4Aw8AXn3H+nea0NwAaAmpqaFZs2bRpX0W1tbZSXl4/ruZds/VOcGS9d8pcjtvvTn3cwpzTE/1lRPKn1TQbVNzH5Xh/kf42qb/zWrVv3gnNuZbplkSy9RwRYCqwFFgBPmtmFzrmW1EbOuXuBewFWrlzp1q5dO643a2hoYLzP5a3ZEO8a9fnvOvoSj+9o4sorr8TMJq++SaD6Jibf64P8r1H15UYmXS4HgdqU6QX+vFQHgM3OuV7n3Bt4W+tLs1Nilo1yYlGf+rpqmtt72NfcMQlFiYhMXCaB/hyw1MwWmVkMuBHYPKTND/C2zjGz2cA5wN7slZlFGewUBe8SAICORxeRaWPUQHfOxYGNwKPA68CDzrnXzOwOM7vOb/YocNzMtgNbgM85547nqugJGeXEoj7n1JRTGgvrjFERmTYy6kN3zj0CPDJk3udTxh3wB/4jv4VGP8oFIBIOcdGCGbolnYhMGwV6pmj6y+cOVV9XzfZDJ+nqTeS4KBGRiSvAQM9sCx2gvraKeNLx6kGdYCQi+a8wAz2DPnSAS/qvvNiSu3pERLKkAAM9s8MWAeZWFLOgukQX6hKRaaHwAn2UOxYNVV9XrS10EZkWCi/Qx7CFDl4/+uHWLt5u7cphUSIiE1eAgR4Fl4BkMqPmfXcw0oW6RCTfFWagQ8Y7RpefWUksHFK3i4jkvcIL9JAf6K/9AOLdozYvioRZfmalAl1E8l7hBfqid8OMWvj+BrjrXPjvP4Wm10d8Sn1dFS8fbKE3kVk3jYjIVCi8QD+zHj77Etz8H7BoDTx7L3z1HXDfVfDiv0J322lPqa+rpqs3yc63T01BwSIimSm8QAcIhWHJVfDhf4E/3AFX/yV0nYTNvwt3LfOG+58D/+Yf9f1XXtSOURHJX4UZ6KnKZsPlG+Ezz8DHH4PlH4BXHoJvXgVffSf8z1dZUNTB7PIi9aOLSF5ToPcxg7rV8IF74A93wq9+GWKl8OifYH93Hl8t+gr2RkPGhzuKiEw2BXo6xZWw4lb45BPwqV/Ayo9zUfeL3NX15yS+fDE8+bfQozsZiUh+UaCP5owL4Jo72fbhZ/jdno2cLJoPT/yFtyN190+mujoRkX4K9AxduHAuP3KX889Lvgy3/ggiRfDtG+DBj8HJw1NdnoiIAj1TZUURlp1R6d3B6Kwr4FNPwbo/g50/hrsvg2e+DkndCENEpo4CfQzq66rYtr+FZNJ5W+hXfg4+/T9Qexn8+I/hvvfCoW1TXaaIFCgF+hhcUlvFqa44e4+lnHw0azHc/J/wa9+E1oPwjXUs2f0N77h2EZFJpEAfg0v9Ky++OPR4dDO48AbY+Bys/DjzD/4I7lkF2x/uPzlJRCTXFOhjcPbsciqKI8OfYFRSBb9yFy9eeqd3wtKDvwHf+TCceGsyyxSRfOUc/OxL0NaUk5dXoI9BKGRcUls16iUATlUug082wPv+Ct78BdyzGp76+zHdWENEAuinX4AtX4RX/zMnL69AH6P6ump2HjnFF3+4ncam0y/k1S8cgXd+BjY+C0ve6/0iv74G9j09abWKSB55+mvwi3+AlR+H1b+dk7eI5ORVA+zWy8+isekU3/rlm9z31BusXjSTj6yuY/0FZ1AUCZ/+hBkL4MZvw45HvCNh7n8fXPhhqHuHt0N11hKoOBNC+m4VCaxXHoL/vg3O+1W49m+9/W45oEAfo5llMb760RU0nerioRcO8MCz+/jspm1Ul0a5YcUCblpVl/6J517rXa73Z38Nz30TXnlwYFmkGGae7T1mLfGCfuZib1hek7NfvohMgr0N8P1PwcJ3wYfu8672miMK9HGaW1HMp9cu4VNrFvNU4zEeeHYf//yLN/nGz9/gvJkhTlYf4n3n1wzeai8qh6u/CFfdAacOwfE90LzHGx7fA8d2wa5HB98eL1buB/1i3MzFtJTU0lpSy8KFZ2MV8yBaPPk/vIhk5vBLsOlmmL0UbvxOzv9eFegTFAoZa86Zw5pz5tB0sovvvXCAf35yF7/3wFZmlsX49RULuHFVHYtml6U+yeuKmbEAzr5y8AsmE7iWfbQe2MGxfdvpPrKb8Ik3mHH0aebEH6baklSnNHfFM7DyM6CiBgYNz/C27iv88aKKSVkfIuJrfgP+/Qbv6Leb/8Mb5pgCPYvmVhbzmXVLOI/9hOdfwAPP7OO+p97g60/u5fLFs/jI6jquXn4GschAf/nxtm52HWlj15FT7Dpyit1H2th55BStnUngXOBcZpXFOKemgnPnFnNJRStl7Qd47tXXiLQf5dyidi6L9VDT24rtfxpOHYFEmnulRsv6w/78DgfND0Ak5nX3RIogXDQw3v8ohnBKm75hUaXXNaR+f5H02o7Cv3/I+2/75h9C5ZmT8rYK9BwImXHlOXO40t9qf/D5/Tzw7H42fmcrs8pirF02l0Mtnew6corj7T39z5tREuWcmnLef9E8zqmpYGlNOefUVDC7vOi097jyV5I8vO0Qf7+lkb1721k6t5yN71nC+y+cR7in1Qv2trfTDks73oR9hyDRA/Eu72bZ8S5wY7jWe3GVd02bvsfc8xXwIuDdxvI7v+5dtO9jm2HOskl7awV6js2tLGbje5byO2uX8PPdR3ng2X1s2dnEwlmlXHVeDUtryll2RgXn1FQwt6IIy3AHaDQc4oYVC/hg/Xx+9Mph7n5iN5/dtI1/+OluPr12MR+oP4fo3HPTPve5hgbWrl17+oJEfCDgE90pYd89EPqJHmg/Cm/9Et58Cnb80HuuAl4E4j3w4C1w+GWvz7x21aS+vQJ9koRDxtplc1m7bG7WX/e6i8/k/RfO47Htb/OVJxr53EMv8+XHd/M7axdzw4oF6Q+nTPtiEQiXeztvR3PJR7xh6wHv5Kk3f66Al8KWTMLmjbDnCbjubli2ftJLUKAHRChkrL9gHu87/wy27GziHx9v5Pbvv8rdTzTy22vO5sZVdRRHc3C41IwFcPH/9h4ALfvhrVECvnYVlM3x+uKLKnJ6GJfIpPnp5+Hl78J7/gwuvWVKSlCgB4yZ8Z5za1i3bC5PNR7jK4838oX/2s7dW/awYc0iPrp6YW4LqKqFqhvh4hu96eECPlWs3Av34kooquSi9l44etZA4BfPSBmvhGip1/3T0wG97d6wpz39eG8H9LSljLd7l2CoPBOq6oY8FnrDstk69l/G5pd3wy+/Apd9Et79R1NWhgI9oMyMdy+dw7uXzuGZvcf5yhON/NUjO/hawx7WzIP43CMsnFVK7czS3Gy590kX8Ie2QleLd4nh7pPQfcofb4XuU0RaD8LbrwzMj3dm9l6hCMTKvCN6YqUD46WzYEatNx0r89qdPAgt++Dg89A55No8kZI0YZ8S+LqCpqR6+Xvw2O2w/Hq45s4p3RjIKNDNbD3wZSAM3Oec++th2v0a8BBwmXPu+axVKROy+uxZrD57Fi+8dYJ7tjTy8I4mHt7j/XrM4IzKYhbOKmXhzDIWzvaHs0pZOKuUiuJodoupqvUeI3hx6E7bRK8f7q3eF0BPB0RL/MAu9cI7WuYdhjkeXSehdb8X8P2Pt4YN/HeHYrB1LpRWe18WJTO9YeksKPXHS6oHT0dLtdUfRHuegB/8Diy8Aj5475R3H44a6GYWBu4B/hdwAHjOzDY757YPaVcBfBZ4JheFysStWFjN/bdexg8f28L8cy9hX3MHbx7r4K3mdt463sHjO45wrK1n0HNmlcWom1XKWbPKqJtZylmzS5lfVUpRJEQkbETDISIhfxg2wiEjGhq8LByyjI/eSSsc9YNx5gTXwDCKK6H4fKg5P/3yIYF/6JVfUjurFDqOQ2ezN7+j2fuvYziR4pTgr/a6maKlA/819H0x9c8fbtxvH45N/ReEc/6hr93el27CPxoq0ePP70mZl7LcJZnR0gQnl3knvU31zzFeh7bCd2/xDku8KfdngWYiky30VUCjc24vgJltAq4Htg9p9xfAncDnslqhZF15zKivq6a+rvq0ZW3dcd463s6+4x28ebyDfc3tvHmsg2ffaOYH2w6Ou7chGjYiIS/gi2NhzppVypK55SyeU87iueUsmVPO/KoSQqE8/OMeEvh7OpdRO9xhn10tXtB3NA8Efv90sz/dDB37T+/zH8t5AKGodzRSUQXEKlLGveHioy2Q/IU3r6jcb+OPR0u9YO1p9/cvtKWMt58+3t02ZFm7F86JnlHLHE49wLbbvf+sZp4NMxcNvobRzMVQPjd/w755L3z7170v6Y8+5O3nyQPmRvkLNbMbgPXOuU/407cAq51zG1PaXArc7pz7NTNrAP4oXZeLmW0ANgDU1NSs2LRp07iKbmtro7w8g0PrpkhQ6+tJOI51Opq7HPGkI+HwHklIOOcPGRg6N2g67rfrTsDb7UkOtyU5lXrZmjDMKwsxpyhBXVWMeWUhziwLUVNmRPIo6HPy+3WOULKXcKKLULKLcOL0RyjZ7Y93Ek50EYl3+OOdROJ9Q29eKN5BNNk19jIIEY+UkAgXkwgPNywiGYrhLEoyFCUZigwZj/jj0bTjzgx3Yj8zOUFJ5yFKOw5T0nmI4q4jhNzAjdbj4WI6S+bRWXJm/7Cj9Ey6imtIhqKYc4D3MJf0h6nTAMmUeQ7w5nu1xPxH1Pt5UrpLRvodR3tauPTF/0sk3s6Ll/41naULxryeJ2LdunUvOOdWpls24Z2iZhYC/g64dbS2zrl7gXsBVq5c6dKe3JKBhuFOjMkTqi9zze09NDa10djUxp6j3vDVfcd4/uhA0odDxsKZpSz2t+jPnl1GZUmEkliEsliY0liE0liY0qIwZbEIJdFwTrf082n9DaehoYG1a9Z4W/7dbd4+iJ5T3nhvh9cFFCsf6MKJeecfWDhG1Iws7zlJW985Q9dhIg6t+7yt3+N7iTTvoeL4Hiqa98D+pyEl7HPCwv2Xt+hOGEVlladf9iJSDMd3Q+Ik3PpfrF6QNlenTCaBfhBI3Yu1wJ/XpwK4AGjw+0nPADab2XXaMSqjmVkWY9WimaxaNNA/3tDQwKrLr2Dv0fb+kO8L/IadTfQmRu/3KYmGB4d8zBuWxsKUFUWYURKlqjRKVUmUqtKYN14ao6okSnVpjIriSH52/4xFKOR3s1QA86a6mtGFIwOXkV4yZFmi19tX0bwXTrwJyQRYyOuSMfPG8Yf980ND5vttMe/1Ui970T/0xpv3v8G8OTNPb9PV4q3Pa78EeRbmkFmgPwcsNbNFeEF+I/CRvoXOuVZgdt/0SF0uIpkqjUW4YP4MLpg/uG8ynkhyuLWLtu44HT1x2rsTdPQkvPGeBJ398+L+/ATt3fH+NsfaumnrjtPa2cuprviw72/mXVtnUOD74yeO9LAn8gYVxREqiyNUFkepKI5SURzxH9FBF2CTLAhH/RvCLJ6Ut9vZ0MC8PP8vLJ1RA905FzezjcCjeIct3u+ce83M7gCed85tznWRIn0i4RC1M0uz8lrxRJLWzl5aOntp6eiltbOHE+3edGtHDy2dvZzo6KWlo4fm9h72Hm3nREcPp7riPLxn6DEBgxVHQ/0hXzlkWFEcoTgapigSoigSpiga6h8vjvrzIiF//vDtJnTkkARSRn3ozrlHgEeGzPv8MG3XTrwskdyLhEPMKi9iVpqrWY7kiS1bWLH6Ck529XKyy9vSP9UV52RnL6f6prv7puP9bQ62dPpte+mOJyd0flLIoLzI+2+grChMeVGE8uIo5f54y9FuXuzZSXlxhPIir01FynhJNExxdGBYFAlN/y4m0ZmiImMVMmNGaZQZpePfdeicozfh6I4n6I4nvUfvMOPxBN293nhXb4KueIKO7gRt3d4XSXt3nDb/C+RQSydtXXFaO+L8ZF/jmL40iiIhSmJhiv3/AIoHhf7AsqJomHDIWw8hM8z6xvGnB8ZD5p21PKhNyDj0Vi/NLx7wv4i8/176xiuKI5lfUE4GUaCLTAEzIxYxYpEQubiXVENDA2vWXElHr7cPITX4T3XF6Y4n6OxJ0NWboLPX/6Lo7ZtO0OXP6+z1vkyOtfUMWuacI+kcSQdJ53D+sG+eG7IsnX9//aVh64+FQ/3hXl4U6f9vpG+6KBIilvoIhwbPC4eJRUJEw946LkqZF4uE6PtnxPBGUnuvzOBYZ5KDLZ1+m4H5fe37fta+nzuRHPxze9Pe8kR/24Fli2aXUVOZ/RORFOgiARUKWX8Y1lROXR0uJfgcXqA9tuVJLrp0Vf8XzKmuXtpSvnAGzfOnD7Z00tbtdV/1xJP0xJPEkzm8rs7PnsjZS3/xAxdw8zuyf6E8BbqI5FR/l4u/dRsNQ2XMOCv1PrvjlEg6ehNed1RPPElPItkf9t6013XVm3CD5jk3cI01h/el0zcOsGPHDs5ddi7On+PcwDLn6O86Su1q8qYHdz958711ELaB9mfPyc2Jhwp0EZm2wiEjHApn/YqhDW17WHvZyBeRy0c6WFZEJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAIio0A3s/VmttPMGs3stjTL/8DMtpvZy2b2uJktzH6pIiIyklED3czCwD3ANcBy4CYzWz6k2VZgpXPuIuAh4G+yXaiIiIwsky30VUCjc26vc64H2ARcn9rAObfFOdfhTz4NLMhumSIiMhpzzo3cwOwGYL1z7hP+9C3AaufcxmHa3w287Zz7YpplG4ANADU1NSs2bdo0rqLb2tooLy8f13Mng+qbGNU3cfleo+obv3Xr1r3gnFuZdqFzbsQHcANwX8r0LcDdw7S9GW8LvWi0112xYoUbry1btoz7uZNB9U2M6pu4fK9R9Y0f8LwbJlcjGXwhHARqU6YX+PMGMbOrgNuBK51z3Zl+24iISHZk0of+HLDUzBaZWQy4Edic2sDM6oGvA9c555qyX6aIiIxm1EB3zsWBjcCjwOvAg86518zsDjO7zm/2JaAc+J6ZbTOzzcO8nIiI5EgmXS445x4BHhky7/Mp41dluS4RERkjnSkqIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiARERoFuZuvNbKeZNZrZbWmWF5nZd/3lz5jZWVmvVERERjRqoJtZGLgHuAZYDtxkZsuHNPst4IRzbgnw98Cd2S5URERGlskW+iqg0Tm31znXA2wCrh/S5nrgX/zxh4D3mpllr0wRERlNJIM284H9KdMHgNXDtXHOxc2sFZgFHEttZGYbgA3+ZJuZ7RxP0cDsoa+dZ1TfxKi+icv3GlXf+C0cbkEmgZ41zrl7gXsn+jpm9rxzbmUWSsoJ1Tcxqm/i8r1G1ZcbmXS5HARqU6YX+PPStjGzCDADOJ6NAkVEJDOZBPpzwFIzW2RmMeBGYPOQNpuBj/njNwBPOOdc9soUEZHRjNrl4veJbwQeBcLA/c6518zsDuB559xm4JvAv5lZI9CMF/q5NOFumxxTfROj+iYu32tUfTlg2pAWEQkGnSkqIhIQCnQRkYDI60DP50sOmFmtmW0xs+1m9pqZfTZNm7Vm1mpm2/zH5yerPv/93zSzV/z3fj7NcjOzf/TX38tmdukk1rYsZb1sM7OTZvb7Q9pM+vozs/vNrMnMXk2ZN9PMfmJmu/1h9TDP/ZjfZreZfSxdmxzU9iUz2+H//r5vZlXDPHfEz0KOa/yCmR1M+T1eO8xzR/x7z2F9302p7U0z2zbMcydlHU6Icy4vH3g7YPcAZwMx4CVg+ZA2nwb+yR+/EfjuJNY3D7jUH68AdqWpby3wwylch28Cs0dYfi3wY8CAdwDPTOHv+m1g4VSvP2ANcCnwasq8vwFu88dvA+5M87yZwF5/WO2PV09CbVcDEX/8znS1ZfJZyHGNXwD+KIPPwIh/77mqb8jyu4DPT+U6nMgjn7fQ8/qSA865w865F/3xU8DreGfMTifXA//qPE8DVWY2bwrqeC+wxzn31hS89yDOuSfxjtRKlfo5+xfgA2me+j7gJ865ZufcCeAnwPpc1+ace8w5F/cnn8Y7T2TKDLP+MpHJ3/uEjVSfnx0fBh7I9vtOlnwO9HSXHBgamIMuOQD0XXJgUvldPfXAM2kWv9PMXjKzH5vZ+ZNbGQ54zMxe8C+7MFQm63gy3Mjwf0RTuf761DjnDvvjbwM1adrkw7r8ON5/XOmM9lnItY1+t9D9w3RZ5cP6ezdwxDm3e5jlU70OR5XPgT4tmFk58B/A7zvnTg5Z/CJeN8LFwFeAH0xyeVc45y7Fu1LmZ8xszSS//6j8k9WuA76XZvFUr7/TOO9/77w71tfMbgfiwLeHaTKVn4WvAYuBS4DDeN0a+egmRt46z/u/p3wO9Ly/5ICZRfHC/NvOuf8cutw5d9I51+aPPwJEzWz2ZNXnnDvoD5uA7+P9W5sqk3Wca9cALzrnjgxdMNXrL8WRvq4of9iUps2UrUszuxV4P/BR/wvnNBl8FnLGOXfEOZdwziWBbwzz3lP6WfTz40PAd4drM5XrMFP5HOh5fckBv7/tm8Drzrm/G6bNGX19+ma2Cm99T8oXjpmVmVlF3zjezrNXhzTbDPyGf7TLO4DWlK6FyTLsVtFUrr8hUj9nHwMeTtPmUeBqM6v2uxSu9ufllJmtB/4YuM451zFMm0w+C7msMXW/zAeHee9M/t5z6Spgh3PuQLqFU70OMzbVe2VHeuAdhbELb+/37f68O/A+vADFeP+qNwLPAmdPYm1X4P3r/TKwzX9cC3wK+JTfZiPwGt4e+6eByyexvrP9933Jr6Fv/aXWZ3g3L9kDvAKsnOTfbxleQM9ImTel6w/vy+Uw0IvXj/tbePtlHgd2Az8FZvptVwL3pTz34/5nsRH4zUmqrRGv77nvM9h31NeZwCMjfRYmcf39m//5ehkvpOcNrdGfPu3vfTLq8+d/q+9zl9J2StbhRB469V9EJCDyuctFRETGQIEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQmI/w+5tl8n1j9GEQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Neural Network with Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5755 - val_loss: 304.5009\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 86.4787 - val_loss: 8021.8843\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "162/162 [==============================] - 0s 1ms/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "# train\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# evaluate\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### that training diverged. \n",
    "\n",
    "# use multiple inputs instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soeren/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7816 - val_loss: 0.8842\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7227 - val_loss: 0.6985\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6277 - val_loss: 0.6416\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5805 - val_loss: 0.6021\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5514 - val_loss: 0.5871\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5302 - val_loss: 0.5673\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5162 - val_loss: 0.5577\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5026 - val_loss: 0.5391\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4941 - val_loss: 0.5289\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4847 - val_loss: 0.5223\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4780 - val_loss: 0.5198\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4713 - val_loss: 0.5124\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4657 - val_loss: 0.5043\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4606 - val_loss: 0.4985\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4559 - val_loss: 0.4924\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4517 - val_loss: 0.4890\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4475 - val_loss: 0.4935\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4440 - val_loss: 0.4832\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4402 - val_loss: 0.4862\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4362 - val_loss: 0.4753\n",
      "162/162 [==============================] - 0s 875us/step - loss: 0.4723\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9825 - main_output_loss: 0.8514 - auxiliary_output_loss: 2.1626 - val_loss: 0.7474 - val_main_output_loss: 0.6564 - val_auxiliary_output_loss: 1.5662\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5678 - main_output_loss: 0.4876 - auxiliary_output_loss: 1.2896 - val_loss: 0.8043 - val_main_output_loss: 0.7395 - val_auxiliary_output_loss: 1.3873\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5169 - main_output_loss: 0.4495 - auxiliary_output_loss: 1.1236 - val_loss: 0.5256 - val_main_output_loss: 0.4636 - val_auxiliary_output_loss: 1.0842\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4810 - main_output_loss: 0.4265 - auxiliary_output_loss: 0.9716 - val_loss: 0.5097 - val_main_output_loss: 0.4624 - val_auxiliary_output_loss: 0.9357\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4613 - main_output_loss: 0.4180 - auxiliary_output_loss: 0.8507 - val_loss: 0.4828 - val_main_output_loss: 0.4447 - val_auxiliary_output_loss: 0.8263\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4447 - main_output_loss: 0.4093 - auxiliary_output_loss: 0.7630 - val_loss: 0.4759 - val_main_output_loss: 0.4452 - val_auxiliary_output_loss: 0.7524\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4371 - main_output_loss: 0.4084 - auxiliary_output_loss: 0.6959 - val_loss: 0.4540 - val_main_output_loss: 0.4275 - val_auxiliary_output_loss: 0.6919\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4254 - main_output_loss: 0.3999 - auxiliary_output_loss: 0.6545 - val_loss: 0.4471 - val_main_output_loss: 0.4247 - val_auxiliary_output_loss: 0.6487\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4138 - main_output_loss: 0.3909 - auxiliary_output_loss: 0.6197 - val_loss: 0.4474 - val_main_output_loss: 0.4260 - val_auxiliary_output_loss: 0.6400\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4051 - main_output_loss: 0.3834 - auxiliary_output_loss: 0.6001 - val_loss: 0.4345 - val_main_output_loss: 0.4161 - val_auxiliary_output_loss: 0.6000\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3970 - main_output_loss: 0.3767 - auxiliary_output_loss: 0.5797 - val_loss: 0.4231 - val_main_output_loss: 0.4046 - val_auxiliary_output_loss: 0.5893\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - main_output_loss: 0.3728 - auxiliary_output_loss: 0.5662 - val_loss: 0.4212 - val_main_output_loss: 0.4044 - val_auxiliary_output_loss: 0.5730\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3878 - main_output_loss: 0.3691 - auxiliary_output_loss: 0.5557 - val_loss: 0.4094 - val_main_output_loss: 0.3908 - val_auxiliary_output_loss: 0.5769\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - main_output_loss: 0.3668 - auxiliary_output_loss: 0.5445 - val_loss: 0.4103 - val_main_output_loss: 0.3947 - val_auxiliary_output_loss: 0.5504\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3821 - main_output_loss: 0.3649 - auxiliary_output_loss: 0.5362 - val_loss: 0.4051 - val_main_output_loss: 0.3900 - val_auxiliary_output_loss: 0.5405\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3757 - main_output_loss: 0.3587 - auxiliary_output_loss: 0.5294 - val_loss: 0.4051 - val_main_output_loss: 0.3892 - val_auxiliary_output_loss: 0.5486\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3730 - main_output_loss: 0.3564 - auxiliary_output_loss: 0.5221 - val_loss: 0.4090 - val_main_output_loss: 0.3923 - val_auxiliary_output_loss: 0.5589\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3694 - main_output_loss: 0.3531 - auxiliary_output_loss: 0.5162 - val_loss: 0.4154 - val_main_output_loss: 0.4000 - val_auxiliary_output_loss: 0.5540\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3656 - main_output_loss: 0.3496 - auxiliary_output_loss: 0.5097 - val_loss: 0.3920 - val_main_output_loss: 0.3764 - val_auxiliary_output_loss: 0.5325\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3621 - main_output_loss: 0.3465 - auxiliary_output_loss: 0.5026 - val_loss: 0.3984 - val_main_output_loss: 0.3836 - val_auxiliary_output_loss: 0.5313\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3980 - main_output_loss: 0.3835 - auxiliary_output_loss: 0.5289\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe32ff0bd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# same model, but with auxiliary output for the deep part\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='auxiliary_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "# multiple outputs means multiple loss functions - and weights for them!\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# same model using subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(my_name)\n",
    "# model = keras.models.load_model(my_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9903 - main_output_loss: 0.8131 - auxiliary_output_loss: 2.5853 - val_loss: 0.9516 - val_main_output_loss: 0.8881 - val_auxiliary_output_loss: 1.5226\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5836 - main_output_loss: 0.5111 - auxiliary_output_loss: 1.2362 - val_loss: 0.5625 - val_main_output_loss: 0.4949 - val_auxiliary_output_loss: 1.1704\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5004 - main_output_loss: 0.4410 - auxiliary_output_loss: 1.0352 - val_loss: 0.5195 - val_main_output_loss: 0.4666 - val_auxiliary_output_loss: 0.9954\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4802 - main_output_loss: 0.4351 - auxiliary_output_loss: 0.8865 - val_loss: 0.4903 - val_main_output_loss: 0.4490 - val_auxiliary_output_loss: 0.8618\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4384 - main_output_loss: 0.4012 - auxiliary_output_loss: 0.7737 - val_loss: 0.4614 - val_main_output_loss: 0.4292 - val_auxiliary_output_loss: 0.7514\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4251 - main_output_loss: 0.3952 - auxiliary_output_loss: 0.6942 - val_loss: 0.4442 - val_main_output_loss: 0.4179 - val_auxiliary_output_loss: 0.6807\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4078 - main_output_loss: 0.3812 - auxiliary_output_loss: 0.6474 - val_loss: 0.4249 - val_main_output_loss: 0.4002 - val_auxiliary_output_loss: 0.6475\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3970 - main_output_loss: 0.3728 - auxiliary_output_loss: 0.6145 - val_loss: 0.4257 - val_main_output_loss: 0.4035 - val_auxiliary_output_loss: 0.6254\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3933 - main_output_loss: 0.3714 - auxiliary_output_loss: 0.5908 - val_loss: 0.4221 - val_main_output_loss: 0.3983 - val_auxiliary_output_loss: 0.6362\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3839 - main_output_loss: 0.3624 - auxiliary_output_loss: 0.5778 - val_loss: 0.4238 - val_main_output_loss: 0.4063 - val_auxiliary_output_loss: 0.5813\n"
     ]
    }
   ],
   "source": [
    "# build and compile model again\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='auxiliary_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "# multiple outputs means multiple loss functions - and weights for them!\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')\n",
    "\n",
    "# callback, crude implementation of early stopping\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=10, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[checkpoint_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.3780 - main_output_loss: 0.3579 - auxiliary_output_loss: 0.5594 - val_loss: 0.4039 - val_main_output_loss: 0.3869 - val_auxiliary_output_loss: 0.5574\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3710 - main_output_loss: 0.3515 - auxiliary_output_loss: 0.5463 - val_loss: 0.4084 - val_main_output_loss: 0.3919 - val_auxiliary_output_loss: 0.5570\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3691 - main_output_loss: 0.3505 - auxiliary_output_loss: 0.5370 - val_loss: 0.3979 - val_main_output_loss: 0.3823 - val_auxiliary_output_loss: 0.5382\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3797 - main_output_loss: 0.3608 - auxiliary_output_loss: 0.5503 - val_loss: 0.4458 - val_main_output_loss: 0.4225 - val_auxiliary_output_loss: 0.6556\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3768 - main_output_loss: 0.3601 - auxiliary_output_loss: 0.5272 - val_loss: 0.3824 - val_main_output_loss: 0.3666 - val_auxiliary_output_loss: 0.5240\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3574 - main_output_loss: 0.3409 - auxiliary_output_loss: 0.5057 - val_loss: 0.3901 - val_main_output_loss: 0.3761 - val_auxiliary_output_loss: 0.5154\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3578 - main_output_loss: 0.3418 - auxiliary_output_loss: 0.5024 - val_loss: 0.3841 - val_main_output_loss: 0.3701 - val_auxiliary_output_loss: 0.5101\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3526 - main_output_loss: 0.3377 - auxiliary_output_loss: 0.4866 - val_loss: 0.3756 - val_main_output_loss: 0.3619 - val_auxiliary_output_loss: 0.4991\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3472 - main_output_loss: 0.3322 - auxiliary_output_loss: 0.4817 - val_loss: 0.3778 - val_main_output_loss: 0.3654 - val_auxiliary_output_loss: 0.4888\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3463 - main_output_loss: 0.3317 - auxiliary_output_loss: 0.4774 - val_loss: 0.3790 - val_main_output_loss: 0.3650 - val_auxiliary_output_loss: 0.5056\n"
     ]
    }
   ],
   "source": [
    "# use the official early stopping callback\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=10, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a custom callback\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train: {:.2f}'.format(logs['val_loss'] / logs['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorboard to visualize the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 8s 15ms/step - loss: 1.1465 - main_output_loss: 1.0236 - auxiliary_output_loss: 2.2532 - val_loss: 1.0424 - val_main_output_loss: 1.0079 - val_auxiliary_output_loss: 1.3524\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.5958 - main_output_loss: 0.5388 - auxiliary_output_loss: 1.1092 - val_loss: 0.5664 - val_main_output_loss: 0.5103 - val_auxiliary_output_loss: 1.0711\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.5075 - main_output_loss: 0.4601 - auxiliary_output_loss: 0.9335 - val_loss: 0.5311 - val_main_output_loss: 0.4883 - val_auxiliary_output_loss: 0.9158\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4792 - main_output_loss: 0.4418 - auxiliary_output_loss: 0.8153 - val_loss: 0.5020 - val_main_output_loss: 0.4663 - val_auxiliary_output_loss: 0.8237\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.4523 - main_output_loss: 0.4202 - auxiliary_output_loss: 0.7412 - val_loss: 0.4836 - val_main_output_loss: 0.4535 - val_auxiliary_output_loss: 0.7551\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4370 - main_output_loss: 0.4090 - auxiliary_output_loss: 0.6886 - val_loss: 0.4590 - val_main_output_loss: 0.4325 - val_auxiliary_output_loss: 0.6978\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4261 - main_output_loss: 0.4009 - auxiliary_output_loss: 0.6526 - val_loss: 0.4500 - val_main_output_loss: 0.4254 - val_auxiliary_output_loss: 0.6713\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4182 - main_output_loss: 0.3953 - auxiliary_output_loss: 0.6243 - val_loss: 0.4384 - val_main_output_loss: 0.4165 - val_auxiliary_output_loss: 0.6361\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4063 - main_output_loss: 0.3844 - auxiliary_output_loss: 0.6034 - val_loss: 0.4491 - val_main_output_loss: 0.4294 - val_auxiliary_output_loss: 0.6273\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4020 - main_output_loss: 0.3813 - auxiliary_output_loss: 0.5878 - val_loss: 0.4284 - val_main_output_loss: 0.4081 - val_auxiliary_output_loss: 0.6106\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3942 - main_output_loss: 0.3748 - auxiliary_output_loss: 0.5687 - val_loss: 0.4255 - val_main_output_loss: 0.4077 - val_auxiliary_output_loss: 0.5860\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4051 - main_output_loss: 0.3886 - auxiliary_output_loss: 0.5539 - val_loss: 0.4304 - val_main_output_loss: 0.4155 - val_auxiliary_output_loss: 0.5653\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3854 - main_output_loss: 0.3679 - auxiliary_output_loss: 0.5433 - val_loss: 0.4172 - val_main_output_loss: 0.4023 - val_auxiliary_output_loss: 0.5510\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3762 - main_output_loss: 0.3592 - auxiliary_output_loss: 0.5297 - val_loss: 0.3997 - val_main_output_loss: 0.3842 - val_auxiliary_output_loss: 0.5385\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3682 - main_output_loss: 0.3515 - auxiliary_output_loss: 0.5187 - val_loss: 0.4231 - val_main_output_loss: 0.4103 - val_auxiliary_output_loss: 0.5381\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3692 - main_output_loss: 0.3535 - auxiliary_output_loss: 0.5112 - val_loss: 0.3947 - val_main_output_loss: 0.3819 - val_auxiliary_output_loss: 0.5099\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3611 - main_output_loss: 0.3457 - auxiliary_output_loss: 0.5003 - val_loss: 0.4045 - val_main_output_loss: 0.3918 - val_auxiliary_output_loss: 0.5194\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3556 - main_output_loss: 0.3404 - auxiliary_output_loss: 0.4920 - val_loss: 0.3809 - val_main_output_loss: 0.3671 - val_auxiliary_output_loss: 0.5052\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3552 - main_output_loss: 0.3409 - auxiliary_output_loss: 0.4841 - val_loss: 0.3853 - val_main_output_loss: 0.3741 - val_auxiliary_output_loss: 0.4865\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3578 - main_output_loss: 0.3446 - auxiliary_output_loss: 0.4770 - val_loss: 0.3733 - val_main_output_loss: 0.3618 - val_auxiliary_output_loss: 0.4768\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3469 - main_output_loss: 0.3333 - auxiliary_output_loss: 0.4697 - val_loss: 0.3945 - val_main_output_loss: 0.3861 - val_auxiliary_output_loss: 0.4701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3446 - main_output_loss: 0.3314 - auxiliary_output_loss: 0.4640 - val_loss: 0.3748 - val_main_output_loss: 0.3640 - val_auxiliary_output_loss: 0.4722\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3415 - main_output_loss: 0.3287 - auxiliary_output_loss: 0.4569 - val_loss: 0.3676 - val_main_output_loss: 0.3571 - val_auxiliary_output_loss: 0.4618\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3407 - main_output_loss: 0.3284 - auxiliary_output_loss: 0.4512 - val_loss: 0.3619 - val_main_output_loss: 0.3518 - val_auxiliary_output_loss: 0.4529\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3368 - main_output_loss: 0.3245 - auxiliary_output_loss: 0.4475 - val_loss: 0.3611 - val_main_output_loss: 0.3511 - val_auxiliary_output_loss: 0.4515\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3336 - main_output_loss: 0.3213 - auxiliary_output_loss: 0.4446 - val_loss: 0.3623 - val_main_output_loss: 0.3528 - val_auxiliary_output_loss: 0.4480\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3322 - main_output_loss: 0.3202 - auxiliary_output_loss: 0.4401 - val_loss: 0.3612 - val_main_output_loss: 0.3515 - val_auxiliary_output_loss: 0.4487\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3316 - main_output_loss: 0.3197 - auxiliary_output_loss: 0.4394 - val_loss: 0.3602 - val_main_output_loss: 0.3506 - val_auxiliary_output_loss: 0.4468\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3293 - main_output_loss: 0.3176 - auxiliary_output_loss: 0.4344 - val_loss: 0.3729 - val_main_output_loss: 0.3644 - val_auxiliary_output_loss: 0.4498\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3306 - main_output_loss: 0.3195 - auxiliary_output_loss: 0.4305 - val_loss: 0.3564 - val_main_output_loss: 0.3471 - val_auxiliary_output_loss: 0.4396\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "\n",
    "# build and compile model again\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='auxiliary_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "# multiple outputs means multiple loss functions - and weights for them!\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=30, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using tf.summary for custom logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar('my_scalar', np.sin(step / 10), step=10)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram('my_hist', data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32x32 RGB images\n",
    "        tf.summary.image('my_images', images * step / 1000, step=step)\n",
    "        texts = ['The step is ' + str(step), 'Its square is ' + str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soeren/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 1.0756 - val_loss: 0.8153\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.6197 - val_loss: 0.6195\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.5429 - val_loss: 0.5610\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4938 - val_loss: 0.5159\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4677 - val_loss: 0.5046\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4533 - val_loss: 0.4841\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4440 - val_loss: 0.4779\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4371 - val_loss: 0.4766\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4312 - val_loss: 0.4829\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4294 - val_loss: 0.4669\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4221 - val_loss: 0.4612\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4170 - val_loss: 0.4618\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4127 - val_loss: 0.4513\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4097 - val_loss: 0.4540\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4064 - val_loss: 0.4499\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4031 - val_loss: 0.4456\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4002 - val_loss: 0.4490\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3979 - val_loss: 0.4388\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3951 - val_loss: 0.4360\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3911 - val_loss: 0.4324\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3882 - val_loss: 0.4308\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3863 - val_loss: 0.4318\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3838 - val_loss: 0.4265\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3831 - val_loss: 0.4230\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3810 - val_loss: 0.4250\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3802 - val_loss: 0.4201\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3780 - val_loss: 0.4231\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3760 - val_loss: 0.4203\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3748 - val_loss: 0.4156\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3743 - val_loss: 0.4201\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3725 - val_loss: 0.4165\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3709 - val_loss: 0.4196\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3701 - val_loss: 0.4124\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3688 - val_loss: 0.4154\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3691 - val_loss: 0.4123\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3669 - val_loss: 0.4104\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3659 - val_loss: 0.4106\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3649 - val_loss: 0.4081\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3649 - val_loss: 0.4062\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3632 - val_loss: 0.4032\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3630 - val_loss: 0.4059\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3627 - val_loss: 0.4077\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3611 - val_loss: 0.4070\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3595 - val_loss: 0.4028\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3598 - val_loss: 0.4042\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3594 - val_loss: 0.4012\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3580 - val_loss: 0.4040\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3596 - val_loss: 0.4031\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3583 - val_loss: 0.4020\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3551 - val_loss: 0.3967\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3554 - val_loss: 0.3960\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3534 - val_loss: 0.3991\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3537 - val_loss: 0.4007\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3527 - val_loss: 0.3937\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3517 - val_loss: 0.3974\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3525 - val_loss: 0.4026\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3512 - val_loss: 0.3910\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3520 - val_loss: 0.3963\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3490 - val_loss: 0.3922\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3502 - val_loss: 0.3917\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3497 - val_loss: 0.3920\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3484 - val_loss: 0.4005\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3460 - val_loss: 0.3882\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3468 - val_loss: 0.3925\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.3954\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3447 - val_loss: 0.3922\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3443 - val_loss: 0.3950\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3439 - val_loss: 0.3912\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3449 - val_loss: 0.3896\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3437 - val_loss: 0.3941\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3444 - val_loss: 0.3939\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3436 - val_loss: 0.3957\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3437 - val_loss: 0.3968\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3653\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe330985550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "# use a wrapper for that model\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {'n_hidden': [0, 1, 2, 3], 'n_neurons': np.arange(1, 100), 'learning_rate': reciprocal(3e-4, 3e-2)}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
