{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "59507d4b7a424780c7daeb44aadd3841b613d4d87d8fb5cbad99945b5c4a9b7a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example for a naive bayes sentiment analyzer from the book \"Natural Language Processing in Action\" by Lane, Howard and Hapke.\n",
    "# i only added a few more comments and made it work without installing the NLPIA package.\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import casual_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# read in the text file \n",
    "movies = pd.read_csv('movieReviewSnippets_GroundTruth.txt', sep='\\t', index_col=0, names=['sentiment', 'text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          sentiment\n",
       "count  10605.000000\n",
       "mean       0.004831\n",
       "std        1.922050\n",
       "min       -3.875000\n",
       "25%       -1.769231\n",
       "50%       -0.080000\n",
       "75%        1.833333\n",
       "max        3.941176"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10605.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.004831</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.922050</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.875000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-1.769231</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.080000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.833333</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.941176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# lets take a quick look at our data\n",
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10605, 20756)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# the reviews are rated from -4 to 4\n",
    "\n",
    "# let's convert them into the bag-of-words representation\n",
    "\n",
    "bags_of_words = []\n",
    "for text in movies.text:\n",
    "    bags_of_words.append(Counter(casual_tokenize(text))) # Counter creates a dict with token: count of token\n",
    "\n",
    "# lets create a Dataframe of bows\n",
    "df_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "# fill all NaN with zero so we can convert them to int\n",
    "df_bows = df_bows.fillna(0).astype(int)\n",
    "\n",
    "# lets see how large our bow table has become\n",
    "df_bows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 10605 reviews include 20756 different tokens\n",
    "# what threw me off at first is: the bag-of-words conversion via the Counter returns dense representations - only actually present tokens are included in the bow representation of a single review.\n",
    "# these become sparse by creating the dataframe - from_records creates one column per unique key in the list of bow representations and fills each column with missing values with NaN (which we then replaced by 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.4"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# lets start with the model itself\n",
    "# warning: this example from the book does not split test and training data!\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(df_bows, movies.sentiment > 0) # this converts the sentiment to a discrete label\n",
    "movies['predicted_sentiment'] = nb.predict(df_bows) * 8 - 4 #convert binary classification to -4 or 4 for comparison.\n",
    "# lets have a look on the models performance\n",
    "movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs()\n",
    "movies.error.mean().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the MAE is 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sentiment  predicted_sentiment  sentiment_ispositive  predicted_ispositive\n",
       "1   2.266667                    4                     1                     1\n",
       "2   3.533333                    4                     1                     1\n",
       "3  -0.600000                   -4                     0                     0\n",
       "4   1.466667                    4                     1                     1\n",
       "5   1.733333                    4                     1                     1\n",
       "6   2.533333                    4                     1                     1\n",
       "7   2.466667                    4                     1                     1\n",
       "8   1.266667                   -4                     1                     0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>predicted_sentiment</th>\n      <th>sentiment_ispositive</th>\n      <th>predicted_ispositive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2.266667</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.533333</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.600000</td>\n      <td>-4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.466667</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.733333</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.533333</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.466667</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.266667</td>\n      <td>-4</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "movies['sentiment_ispositive'] = (movies.sentiment > 0 ).astype(int)\n",
    "movies['predicted_ispositive'] = (movies.predicted_sentiment > 0 ).astype(int)\n",
    "movies['sentiment predicted_sentiment sentiment_ispositive predicted_ispositive'.split()].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9344648750589345"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     sentiment                                               text\n",
      "1_1      -0.90  troubleshooting ad-2500 and ad-2600 no picture...\n",
      "1_2      -0.15  repost from january 13, 2004 with a better fit...\n",
      "1_3      -0.20  does your apex dvd player only play dvd audio ...\n",
      "1_4      -0.10  or does it play audio and video but scrolling ...\n",
      "1_5      -0.50  before you try to return the player or waste h...\n",
      "   troubleshooting   ad    -  2500  and  2600   no  picture  scrolling    b  \\\n",
      "0              1.0  2.0  2.0   1.0  1.0   1.0  1.0      1.0        1.0  1.0   \n",
      "1              NaN  NaN  NaN   NaN  NaN   NaN  NaN      NaN        NaN  NaN   \n",
      "2              NaN  NaN  NaN   NaN  NaN   NaN  NaN      NaN        NaN  NaN   \n",
      "3              NaN  NaN  NaN   NaN  2.0   NaN  NaN      NaN        1.0  NaN   \n",
      "4              1.0  NaN  NaN   NaN  NaN   NaN  NaN      NaN        NaN  NaN   \n",
      "\n",
      "   ...  undone  warrranty  expire  expired  voids  develops  soldier  serving  \\\n",
      "0  ...     NaN        NaN     NaN      NaN    NaN       NaN      NaN      NaN   \n",
      "1  ...     NaN        NaN     NaN      NaN    NaN       NaN      NaN      NaN   \n",
      "2  ...     NaN        NaN     NaN      NaN    NaN       NaN      NaN      NaN   \n",
      "3  ...     NaN        NaN     NaN      NaN    NaN       NaN      NaN      NaN   \n",
      "4  ...     NaN        NaN     NaN      NaN    NaN       NaN      NaN      NaN   \n",
      "\n",
      "   baghdad  harddisk  \n",
      "0      NaN       NaN  \n",
      "1      NaN       NaN  \n",
      "2      NaN       NaN  \n",
      "3      NaN       NaN  \n",
      "4      NaN       NaN  \n",
      "\n",
      "[5 rows x 5687 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'Century's',\n",
       "       'new',\n",
       "       ...\n",
       "       'sligtly', 'owner', '81', 'defectively', 'warrranty', 'expire',\n",
       "       'expired', 'voids', 'baghdad', 'harddisk'],\n",
       "      dtype='object', length=23302)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# lets see how our model performs on a different dataset\n",
    "products = pd.read_csv('amazonReviewSnippets_GroundTruth.txt', sep='\\t', index_col=0, names=['sentiment', 'text'] )\n",
    "\n",
    "bags_of_words = []\n",
    "# we convert these reviews to BoW in the same way as the movie reviews\n",
    "for text in products.text:\n",
    "    bags_of_words.append(Counter(casual_tokenize(text)))\n",
    "df_product_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "\n",
    "df_product_bows = df_product_bows.fillna(0).astype(int)\n",
    "df_all_bows = df_bows.append(df_product_bows)\n",
    "df_all_bows.columns\n",
    "# we now have more columns - this corresponds to more tokens in the product reviews than in the movie reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  Ill  \\\n0    0     0   0         0   0   0    0     0          0    0  ...    0   \n1    0     0   0         0   0   0    0     0          0    0  ...    0   \n2    0     0   0         0   0   0    0     0          0    0  ...    0   \n3    0     0   0         0   0   0    0     0          0    0  ...    0   \n4    0     0   0         0   1   0    2     0          0    0  ...    0   \n\n   slummer  Rashomon  dipsticks  Bearable  Staggeringly  â€™  ve  muttering  \\\n0        0         0          0         0             0  0   0          0   \n1        0         0          0         0             0  0   0          0   \n2        0         0          0         0             0  0   0          0   \n3        0         0          0         0             0  0   0          0   \n4        0         0          0         0             0  0   0          0   \n\n   dissing  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n\n[5 rows x 20756 columns]\n"
     ]
    }
   ],
   "source": [
    "df_product_bows = df_all_bows.iloc[len(movies):][df_bows.columns]\n",
    "# we need to fill the NaN again that stem from the tokens available in the movie reviews, but not the product reviews.\n",
    "df_product_bows = df_product_bows.fillna(0).astype(int)\n",
    "print(df_product_bows.head())\n",
    "products['ispos'] = (products.sentiment > 0).astype(int)\n",
    "products['predicted_ispositive'] = nb.predict(df_product_bows.values).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5572476029328821"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "(products.predicted_ispositive == products.ispos).sum() / len(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}