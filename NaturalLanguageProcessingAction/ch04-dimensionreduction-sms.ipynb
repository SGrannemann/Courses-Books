{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       spam                                               text\nsms0      0  Go until jurong point, crazy.. Available only ...\nsms1      0                      Ok lar... Joking wif u oni...\nsms2!     1  Free entry in 2 a wkly comp to win FA Cup fina...\nsms3      0  U dun say so early hor... U c already then say...\nsms4      0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# this notebook uses a training data set available via the books github to train an LDA (linear discriminant analysis) classifier to detect if a sms is spam or not\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, LatentDirichletAllocation as LDiA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# lets get the data into a dataframe\n",
    "sms = pd.read_csv('sms-spam.csv', index_col=0)\n",
    "\n",
    "sms['spam'] = sms.spam.astype(int)\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n",
    "sms = pd.DataFrame(sms.values, columns=sms.columns, index=index)\n",
    "sms['spam'] = sms.spam.astype(int)\n",
    "print(sms.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9232"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# calculate tf idf vectors for the sms messages\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4837, 9232)\n"
     ]
    }
   ],
   "source": [
    "tfidf_docs = pd.DataFrame(tfidf_docs)\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "print(tfidf_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.065   0.011   \n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.065   0.023   \n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.044   0.000  -0.002  -0.056   \n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.167  -0.072   0.061   \n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.061  -0.045   \n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.166  -0.022   \n",
       "\n",
       "       topic9  topic10  topic11  topic12  topic13  topic14  topic15  \n",
       "sms0   -0.084    0.008   -0.000   -0.007   -0.041   -0.013    0.025  \n",
       "sms1   -0.024   -0.005    0.037   -0.049   -0.007    0.052   -0.038  \n",
       "sms2!   0.051    0.124    0.031   -0.028   -0.009   -0.044    0.048  \n",
       "sms3   -0.108    0.021    0.017   -0.076   -0.037    0.023   -0.064  \n",
       "sms4    0.030    0.028   -0.006   -0.020    0.038   -0.086   -0.025  \n",
       "sms5!   0.063    0.043    0.049    0.056    0.061    0.006    0.005  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.201</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>0.011</td>\n      <td>-0.019</td>\n      <td>-0.053</td>\n      <td>0.039</td>\n      <td>-0.065</td>\n      <td>0.011</td>\n      <td>-0.084</td>\n      <td>0.008</td>\n      <td>-0.000</td>\n      <td>-0.007</td>\n      <td>-0.041</td>\n      <td>-0.013</td>\n      <td>0.025</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.404</td>\n      <td>-0.094</td>\n      <td>-0.078</td>\n      <td>0.051</td>\n      <td>0.100</td>\n      <td>0.047</td>\n      <td>0.023</td>\n      <td>0.065</td>\n      <td>0.023</td>\n      <td>-0.024</td>\n      <td>-0.005</td>\n      <td>0.037</td>\n      <td>-0.049</td>\n      <td>-0.007</td>\n      <td>0.052</td>\n      <td>-0.038</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>-0.030</td>\n      <td>-0.048</td>\n      <td>0.090</td>\n      <td>-0.067</td>\n      <td>0.091</td>\n      <td>-0.044</td>\n      <td>0.000</td>\n      <td>-0.002</td>\n      <td>-0.056</td>\n      <td>0.051</td>\n      <td>0.124</td>\n      <td>0.031</td>\n      <td>-0.028</td>\n      <td>-0.009</td>\n      <td>-0.044</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.329</td>\n      <td>-0.033</td>\n      <td>-0.035</td>\n      <td>-0.016</td>\n      <td>0.052</td>\n      <td>0.056</td>\n      <td>-0.167</td>\n      <td>-0.072</td>\n      <td>0.061</td>\n      <td>-0.108</td>\n      <td>0.021</td>\n      <td>0.017</td>\n      <td>-0.076</td>\n      <td>-0.037</td>\n      <td>0.023</td>\n      <td>-0.064</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.002</td>\n      <td>0.031</td>\n      <td>0.038</td>\n      <td>0.034</td>\n      <td>-0.075</td>\n      <td>-0.093</td>\n      <td>-0.044</td>\n      <td>0.061</td>\n      <td>-0.045</td>\n      <td>0.030</td>\n      <td>0.028</td>\n      <td>-0.006</td>\n      <td>-0.020</td>\n      <td>0.038</td>\n      <td>-0.086</td>\n      <td>-0.025</td>\n    </tr>\n    <tr>\n      <th>sms5!</th>\n      <td>-0.016</td>\n      <td>0.059</td>\n      <td>0.014</td>\n      <td>-0.006</td>\n      <td>0.122</td>\n      <td>-0.040</td>\n      <td>0.005</td>\n      <td>0.166</td>\n      <td>-0.022</td>\n      <td>0.063</td>\n      <td>0.043</td>\n      <td>0.049</td>\n      <td>0.056</td>\n      <td>0.061</td>\n      <td>0.006</td>\n      <td>0.005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# try PCA for dimension reduction first\n",
    "pca = PCA(n_components=16)\n",
    "pca = pca.fit(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_nums, terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            !      \"      #   #150  #5000      $      %      &      '      (  \\\ntopic0 -0.071  0.008 -0.001 -0.000 -0.001  0.003 -0.000 -0.012 -0.007 -0.005   \ntopic1  0.063  0.008  0.000 -0.000 -0.001 -0.001 -0.002 -0.016 -0.016  0.001   \ntopic2  0.071  0.027  0.000  0.001  0.002  0.000  0.001  0.059  0.008  0.019   \ntopic3 -0.059 -0.032 -0.001 -0.000 -0.001  0.001 -0.003 -0.028  0.001 -0.010   \n\n        ...   ü'll      –    —      ‘      ’      “      …      ┾    〨ud  \\\ntopic0  ...  0.003 -0.000 -0.0 -0.004 -0.001 -0.001 -0.002  0.001  0.001   \ntopic1  ...  0.002  0.001 -0.0  0.004 -0.001 -0.001  0.003  0.001  0.001   \ntopic2  ...  0.000  0.001 -0.0  0.002  0.000  0.001  0.002 -0.001 -0.001   \ntopic3  ... -0.001 -0.001  0.0  0.000 -0.000 -0.000  0.001  0.001  0.001   \n\n            鈥  \ntopic0  0.001  \ntopic1  0.001  \ntopic2 -0.001  \ntopic3  0.001  \n\n[4 rows x 9232 columns]\n"
     ]
    }
   ],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms, index=['topic{}'.format(i) for i in range(16)])\n",
    "print(weights.head(4).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            !   ;)    :)  half  off  free  crazy  deal  only    $   80    %\ntopic0   -7.1  0.1  -0.5  -0.0 -0.4  -2.0   -0.0  -0.1  -2.2  0.3 -0.0 -0.0\ntopic1    6.3  0.0   7.4   0.1  0.4  -2.3   -0.2  -0.1  -3.8 -0.1 -0.0 -0.2\ntopic2    7.1  0.2  -0.1   0.0  0.3   4.4    0.1  -0.1   0.7  0.0  0.0  0.1\ntopic3   -5.9 -0.3  -7.1   0.2  0.3  -0.2    0.0   0.1  -2.3  0.1 -0.1 -0.3\ntopic4   38.1 -0.1 -12.4  -0.1 -0.2   9.9    0.1  -0.2   3.0  0.3  0.1 -0.1\ntopic5  -26.4  0.1  -1.5  -0.4 -0.7  -1.4   -0.6  -0.2  -1.8 -0.9  0.0  0.0\ntopic6  -11.1 -0.5  19.8  -0.4 -0.9  -0.6   -0.2  -0.1  -1.4 -0.0 -0.0 -0.1\ntopic7   16.6  0.1 -17.8   0.7  0.8  -2.9    0.0   0.1  -1.9 -0.3  0.0 -0.1\ntopic8   34.0  0.1   5.3  -0.4 -0.6   0.1   -0.4  -0.4   3.2 -0.6 -0.0 -0.2\ntopic9    7.5 -0.3  16.4   1.4 -0.9   6.3   -0.5  -0.4   3.2 -0.5 -0.0  0.0\ntopic10 -32.2 -0.2 -10.3   0.1  0.1  12.3    0.1   0.0   0.3 -0.0 -0.0 -0.2\ntopic11  19.0  0.4  29.6   0.5  1.3  -4.9    0.1   0.2   0.0 -0.5 -0.0 -0.4\ntopic12  26.7  0.1 -31.8   0.0 -0.1   3.7    0.5  -0.1  -3.6 -0.4  0.0 -0.3\ntopic13   6.4 -0.2  38.8  -0.1  0.6   5.4    0.3   0.2  -1.8 -0.2  0.0 -0.1\ntopic14  -0.8 -0.1  16.7  -0.2 -0.8   6.0    0.2  -0.1   3.8  0.0  0.1 -0.4\ntopic15  -3.2 -0.5   2.6  -0.2 -1.5  -2.6   -0.8   0.5   1.6 -0.5  0.1 -0.3\n"
     ]
    }
   ],
   "source": [
    "# lets find discount spam sms predicting words\n",
    "deals = weights['! ;) :) half off free crazy deal only $ 80 %'.split()].round(3) * 100\n",
    "print(deals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "topic0    -11.9\ntopic1      7.5\ntopic2     12.7\ntopic3    -15.5\ntopic4     38.4\ntopic5    -33.8\ntopic6      4.5\ntopic7     -4.7\ntopic8     40.1\ntopic9     32.2\ntopic10   -30.0\ntopic11    45.3\ntopic12    -5.3\ntopic13    49.3\ntopic14    24.4\ntopic15    -4.8\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(deals.T.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.066   0.012   \n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.065   0.023   \n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  -0.000  -0.001  -0.057   \n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.166  -0.074   0.063   \n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.061  -0.045   \n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.167  -0.023   \n",
       "\n",
       "       topic9  topic10  topic11  topic12  topic13  topic14  topic15  \n",
       "sms0   -0.083    0.007   -0.007    0.002   -0.036   -0.014    0.037  \n",
       "sms1   -0.024   -0.004    0.036    0.043   -0.021    0.051   -0.042  \n",
       "sms2!   0.051    0.125    0.023    0.026   -0.020   -0.042    0.052  \n",
       "sms3   -0.108    0.022    0.023    0.073   -0.046    0.022   -0.070  \n",
       "sms4    0.029    0.028   -0.009    0.027    0.034   -0.083   -0.021  \n",
       "sms5!   0.064    0.041    0.055   -0.037    0.075   -0.001    0.020  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.201</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>0.011</td>\n      <td>-0.019</td>\n      <td>-0.053</td>\n      <td>0.039</td>\n      <td>-0.066</td>\n      <td>0.012</td>\n      <td>-0.083</td>\n      <td>0.007</td>\n      <td>-0.007</td>\n      <td>0.002</td>\n      <td>-0.036</td>\n      <td>-0.014</td>\n      <td>0.037</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.404</td>\n      <td>-0.094</td>\n      <td>-0.078</td>\n      <td>0.051</td>\n      <td>0.100</td>\n      <td>0.047</td>\n      <td>0.023</td>\n      <td>0.065</td>\n      <td>0.023</td>\n      <td>-0.024</td>\n      <td>-0.004</td>\n      <td>0.036</td>\n      <td>0.043</td>\n      <td>-0.021</td>\n      <td>0.051</td>\n      <td>-0.042</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>-0.030</td>\n      <td>-0.048</td>\n      <td>0.090</td>\n      <td>-0.067</td>\n      <td>0.091</td>\n      <td>-0.043</td>\n      <td>-0.000</td>\n      <td>-0.001</td>\n      <td>-0.057</td>\n      <td>0.051</td>\n      <td>0.125</td>\n      <td>0.023</td>\n      <td>0.026</td>\n      <td>-0.020</td>\n      <td>-0.042</td>\n      <td>0.052</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.329</td>\n      <td>-0.033</td>\n      <td>-0.035</td>\n      <td>-0.016</td>\n      <td>0.052</td>\n      <td>0.056</td>\n      <td>-0.166</td>\n      <td>-0.074</td>\n      <td>0.063</td>\n      <td>-0.108</td>\n      <td>0.022</td>\n      <td>0.023</td>\n      <td>0.073</td>\n      <td>-0.046</td>\n      <td>0.022</td>\n      <td>-0.070</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.002</td>\n      <td>0.031</td>\n      <td>0.038</td>\n      <td>0.034</td>\n      <td>-0.075</td>\n      <td>-0.093</td>\n      <td>-0.044</td>\n      <td>0.061</td>\n      <td>-0.045</td>\n      <td>0.029</td>\n      <td>0.028</td>\n      <td>-0.009</td>\n      <td>0.027</td>\n      <td>0.034</td>\n      <td>-0.083</td>\n      <td>-0.021</td>\n    </tr>\n    <tr>\n      <th>sms5!</th>\n      <td>-0.016</td>\n      <td>0.059</td>\n      <td>0.014</td>\n      <td>-0.006</td>\n      <td>0.122</td>\n      <td>-0.040</td>\n      <td>0.005</td>\n      <td>0.167</td>\n      <td>-0.023</td>\n      <td>0.064</td>\n      <td>0.041</td>\n      <td>0.055</td>\n      <td>-0.037</td>\n      <td>0.075</td>\n      <td>-0.001</td>\n      <td>0.020</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# try out truncated svd instead\n",
    "svd = TruncatedSVD(n_components=16, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n,            1\n..           1\n...          2\namore        1\navailable    1\nName: sms0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# use LDiA now\n",
    "# start by getting the BOW representation of the sms\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=sms.text).toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(), counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms\n",
    "\n",
    "print(sms.loc['sms0'].text)\n",
    "print(bow_docs.loc['sms0'][bow_docs.loc['sms0'] > 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16, 9232)\n"
     ]
    }
   ],
   "source": [
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "# now we fit that model to our data, which will give us 16 \"topics\" or dimensions\n",
    "ldia = ldia.fit(bow_docs)\n",
    "print(ldia.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n!  184.03   15.00   72.22  394.95   45.48   36.14    9.55   44.81    0.43   \n\"    0.68    4.22    2.41    0.06  152.35    0.06    0.06    0.06    0.45   \n#    0.06    0.06    0.06    0.06    0.06    2.07    0.06    0.06    0.06   \n\n   topic9  topic10  topic11  topic12  topic13  topic14  topic15  \n!   90.23    37.42    44.18    64.40   297.29    41.16    11.70  \n\"    0.68     8.42    11.42     0.07    62.72    12.27     0.06  \n#    0.06     0.06     0.06     1.07     4.05     0.06     0.06  \n"
     ]
    }
   ],
   "source": [
    "components = pd.DataFrame(ldia.components_.T, index=terms, columns=columns)\n",
    "print(components.round(2).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "!       394.952246\n.       218.049724\nto      119.533134\nu       118.857546\ncall    111.948541\n£       107.358914\n,        96.954384\n*        90.314783\nyour     90.215961\nis       75.750037\nName: topic3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(components.topic3.sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\nsms0     0.00    0.62    0.00    0.00    0.00    0.00    0.00    0.00    0.34   \nsms1     0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.78   \nsms2!    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n\n       topic9  topic10  topic11  topic12  topic13  topic14  topic15  \nsms0     0.00     0.00     0.00     0.00     0.00     0.00     0.00  \nsms1     0.01     0.01     0.12     0.01     0.01     0.01     0.01  \nsms2!    0.98     0.00     0.00     0.00     0.00     0.00     0.00  \n"
     ]
    }
   ],
   "source": [
    "# now lets compute the topic vectors for all documents\n",
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors, index=index, columns=columns)\n",
    "print(ldia16_topic_vectors.round(2).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can build a classifier based on LDiA and LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "X_train, X_test, y_train, y_test = train_test_split(ldia16_topic_vectors, sms.spam, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia16_spam'] = lda.predict(ldia16_topic_vectors)\n",
    "print(round(float(lda.score(X_test, y_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n0.748\n"
     ]
    }
   ],
   "source": [
    "# lets compare the result (94% accuracy on test set) to a pure tfidf approach\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_docs, sms.spam.values, test_size=0.5, random_state=271828)\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "print(round(float(lda.score(X_train, y_train)),3))\n",
    "print(round(float(lda.score(X_test, y_test)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}