{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       spam                                               text\nsms0      0  Go until jurong point, crazy.. Available only ...\nsms1      0                      Ok lar... Joking wif u oni...\nsms2!     1  Free entry in 2 a wkly comp to win FA Cup fina...\nsms3      0  U dun say so early hor... U c already then say...\nsms4      0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# this notebook uses a training data set available via the books github to train an LDA (linear discriminant analysis) classifier to detect if a sms is spam or not\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, LatentDirichletAllocation as LDiA\n",
    "\n",
    "\n",
    "\n",
    "# lets get the data into a dataframe\n",
    "sms = pd.read_csv('sms-spam.csv', index_col=0)\n",
    "\n",
    "sms['spam'] = sms.spam.astype(int)\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n",
    "sms = pd.DataFrame(sms.values, columns=sms.columns, index=index)\n",
    "sms['spam'] = sms.spam.astype(int)\n",
    "print(sms.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9232"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# calculate tf idf vectors for the sms messages\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4837, 9232)\n"
     ]
    }
   ],
   "source": [
    "tfidf_docs = pd.DataFrame(tfidf_docs)\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "print(tfidf_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.065   0.014   \n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.066   0.021   \n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.090  -0.044  -0.000  -0.003  -0.054   \n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.166  -0.072   0.061   \n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.062  -0.046   \n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.166  -0.024   \n",
       "\n",
       "       topic9  topic10  topic11  topic12  topic13  topic14  topic15  \n",
       "sms0   -0.083    0.009   -0.008   -0.027   -0.014   -0.006    0.036  \n",
       "sms1   -0.023   -0.008    0.052   -0.031   -0.018    0.035   -0.009  \n",
       "sms2!   0.051    0.129    0.010   -0.042    0.021   -0.003    0.061  \n",
       "sms3   -0.107    0.019    0.043   -0.072   -0.016    0.008   -0.074  \n",
       "sms4    0.030    0.027   -0.003   -0.008    0.061   -0.081    0.016  \n",
       "sms5!   0.062    0.041    0.050    0.082    0.036   -0.002   -0.047  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.201</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>0.011</td>\n      <td>-0.019</td>\n      <td>-0.053</td>\n      <td>0.039</td>\n      <td>-0.065</td>\n      <td>0.014</td>\n      <td>-0.083</td>\n      <td>0.009</td>\n      <td>-0.008</td>\n      <td>-0.027</td>\n      <td>-0.014</td>\n      <td>-0.006</td>\n      <td>0.036</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.404</td>\n      <td>-0.094</td>\n      <td>-0.078</td>\n      <td>0.051</td>\n      <td>0.100</td>\n      <td>0.047</td>\n      <td>0.023</td>\n      <td>0.066</td>\n      <td>0.021</td>\n      <td>-0.023</td>\n      <td>-0.008</td>\n      <td>0.052</td>\n      <td>-0.031</td>\n      <td>-0.018</td>\n      <td>0.035</td>\n      <td>-0.009</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>-0.030</td>\n      <td>-0.048</td>\n      <td>0.090</td>\n      <td>-0.067</td>\n      <td>0.090</td>\n      <td>-0.044</td>\n      <td>-0.000</td>\n      <td>-0.003</td>\n      <td>-0.054</td>\n      <td>0.051</td>\n      <td>0.129</td>\n      <td>0.010</td>\n      <td>-0.042</td>\n      <td>0.021</td>\n      <td>-0.003</td>\n      <td>0.061</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.329</td>\n      <td>-0.033</td>\n      <td>-0.035</td>\n      <td>-0.016</td>\n      <td>0.052</td>\n      <td>0.056</td>\n      <td>-0.166</td>\n      <td>-0.072</td>\n      <td>0.061</td>\n      <td>-0.107</td>\n      <td>0.019</td>\n      <td>0.043</td>\n      <td>-0.072</td>\n      <td>-0.016</td>\n      <td>0.008</td>\n      <td>-0.074</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.002</td>\n      <td>0.031</td>\n      <td>0.038</td>\n      <td>0.034</td>\n      <td>-0.075</td>\n      <td>-0.093</td>\n      <td>-0.044</td>\n      <td>0.062</td>\n      <td>-0.046</td>\n      <td>0.030</td>\n      <td>0.027</td>\n      <td>-0.003</td>\n      <td>-0.008</td>\n      <td>0.061</td>\n      <td>-0.081</td>\n      <td>0.016</td>\n    </tr>\n    <tr>\n      <th>sms5!</th>\n      <td>-0.016</td>\n      <td>0.059</td>\n      <td>0.014</td>\n      <td>-0.006</td>\n      <td>0.122</td>\n      <td>-0.040</td>\n      <td>0.005</td>\n      <td>0.166</td>\n      <td>-0.024</td>\n      <td>0.062</td>\n      <td>0.041</td>\n      <td>0.050</td>\n      <td>0.082</td>\n      <td>0.036</td>\n      <td>-0.002</td>\n      <td>-0.047</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# try PCA for dimension reduction first\n",
    "pca = PCA(n_components=16)\n",
    "pca = pca.fit(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_nums, terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            !      \"      #   #150  #5000      $      %      &      '      (  \\\ntopic0 -0.071  0.008 -0.001 -0.000 -0.001  0.003 -0.000 -0.012 -0.007 -0.005   \ntopic1  0.064  0.008  0.000 -0.000 -0.001 -0.001 -0.002 -0.016 -0.016  0.001   \ntopic2  0.071  0.027  0.000  0.001  0.002  0.000  0.001  0.059  0.008  0.019   \ntopic3 -0.059 -0.032 -0.001 -0.000 -0.001  0.001 -0.003 -0.028  0.001 -0.010   \n\n        ...   ü'll      –    —      ‘      ’      “      …      ┾    〨ud  \\\ntopic0  ...  0.003 -0.000 -0.0 -0.004 -0.001 -0.001 -0.002  0.001  0.001   \ntopic1  ...  0.002  0.001 -0.0  0.004 -0.001 -0.001  0.003  0.001  0.001   \ntopic2  ...  0.000  0.001 -0.0  0.002  0.000  0.001  0.002 -0.001 -0.001   \ntopic3  ... -0.001 -0.001  0.0  0.000 -0.000 -0.000  0.001  0.001  0.001   \n\n            鈥  \ntopic0  0.001  \ntopic1  0.001  \ntopic2 -0.001  \ntopic3  0.001  \n\n[4 rows x 9232 columns]\n"
     ]
    }
   ],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms, index=['topic{}'.format(i) for i in range(16)])\n",
    "print(weights.head(4).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            !   ;)    :)  half  off  free  crazy  deal  only    $   80    %\ntopic0   -7.1  0.1  -0.5  -0.0 -0.4  -2.0   -0.0  -0.1  -2.2  0.3 -0.0 -0.0\ntopic1    6.4  0.0   7.4   0.1  0.4  -2.3   -0.2  -0.1  -3.8 -0.1 -0.0 -0.2\ntopic2    7.1  0.2  -0.1   0.0  0.3   4.4    0.1  -0.1   0.7  0.0  0.0  0.1\ntopic3   -5.9 -0.3  -7.1   0.2  0.3  -0.3    0.0   0.1  -2.3  0.1 -0.1 -0.3\ntopic4   38.0 -0.1 -12.4  -0.1 -0.2   9.9    0.1  -0.2   3.1  0.3  0.1 -0.1\ntopic5  -26.6  0.1  -1.6  -0.3 -0.7  -1.4   -0.6  -0.2  -1.8 -0.9  0.0 -0.0\ntopic6  -10.9 -0.5  19.9  -0.4 -0.9  -0.5   -0.2  -0.1  -1.4 -0.0 -0.0 -0.1\ntopic7   16.0  0.1 -17.4   0.7  0.8  -2.8    0.0   0.0  -1.7 -0.3  0.0 -0.1\ntopic8   35.1  0.2   5.4  -0.4 -0.6  -0.0   -0.4  -0.4   3.1 -0.6 -0.0 -0.2\ntopic9    6.1 -0.3  16.6   1.4 -0.9   6.6   -0.5  -0.4   3.2 -0.5 -0.0 -0.0\ntopic10 -30.4 -0.2 -10.2   0.1  0.1  12.1    0.1   0.0  -0.0 -0.0 -0.0 -0.1\ntopic11  16.3  0.4  42.2   0.4  1.5  -3.7    0.1   0.0   1.7 -0.4 -0.0 -0.4\ntopic12  28.0  0.1  -6.1  -0.0  0.4   6.7    0.8  -0.1  -3.4 -0.4  0.0 -0.5\ntopic13  -3.3 -0.4  32.5  -0.3  0.5   1.1   -0.2   0.3  -1.2 -0.0 -0.0  0.3\ntopic14  -6.5 -0.3  21.8  -0.2 -1.3   7.0   -0.3   0.2   3.1 -0.1  0.1 -0.1\ntopic15 -30.0  0.1   0.4   1.5 -0.4   7.5   -0.2   0.3   0.4  0.1  0.0  0.1\n"
     ]
    }
   ],
   "source": [
    "# lets find discount spam sms predicting words\n",
    "deals = weights['! ;) :) half off free crazy deal only $ 80 %'.split()].round(3) * 100\n",
    "print(deals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "topic0    -11.9\ntopic1      7.6\ntopic2     12.7\ntopic3    -15.6\ntopic4     38.4\ntopic5    -34.0\ntopic6      4.9\ntopic7     -4.7\ntopic8     41.2\ntopic9     31.3\ntopic10   -28.5\ntopic11    58.1\ntopic12    25.5\ntopic13    29.3\ntopic14    23.4\ntopic15   -20.2\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(deals.T.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.066   0.012   \n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.065   0.023   \n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  -0.000  -0.001  -0.057   \n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.166  -0.074   0.063   \n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.061  -0.045   \n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.167  -0.023   \n",
       "\n",
       "       topic9  topic10  topic11  topic12  topic13  topic14  topic15  \n",
       "sms0   -0.083    0.007   -0.007    0.002   -0.036   -0.014    0.037  \n",
       "sms1   -0.024   -0.004    0.036    0.043   -0.021    0.051   -0.042  \n",
       "sms2!   0.051    0.125    0.023    0.026   -0.020   -0.042    0.052  \n",
       "sms3   -0.108    0.022    0.023    0.073   -0.046    0.022   -0.070  \n",
       "sms4    0.029    0.028   -0.009    0.027    0.034   -0.083   -0.021  \n",
       "sms5!   0.064    0.041    0.055   -0.037    0.075   -0.001    0.020  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic0</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n      <th>topic14</th>\n      <th>topic15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sms0</th>\n      <td>0.201</td>\n      <td>0.003</td>\n      <td>0.037</td>\n      <td>0.011</td>\n      <td>-0.019</td>\n      <td>-0.053</td>\n      <td>0.039</td>\n      <td>-0.066</td>\n      <td>0.012</td>\n      <td>-0.083</td>\n      <td>0.007</td>\n      <td>-0.007</td>\n      <td>0.002</td>\n      <td>-0.036</td>\n      <td>-0.014</td>\n      <td>0.037</td>\n    </tr>\n    <tr>\n      <th>sms1</th>\n      <td>0.404</td>\n      <td>-0.094</td>\n      <td>-0.078</td>\n      <td>0.051</td>\n      <td>0.100</td>\n      <td>0.047</td>\n      <td>0.023</td>\n      <td>0.065</td>\n      <td>0.023</td>\n      <td>-0.024</td>\n      <td>-0.004</td>\n      <td>0.036</td>\n      <td>0.043</td>\n      <td>-0.021</td>\n      <td>0.051</td>\n      <td>-0.042</td>\n    </tr>\n    <tr>\n      <th>sms2!</th>\n      <td>-0.030</td>\n      <td>-0.048</td>\n      <td>0.090</td>\n      <td>-0.067</td>\n      <td>0.091</td>\n      <td>-0.043</td>\n      <td>-0.000</td>\n      <td>-0.001</td>\n      <td>-0.057</td>\n      <td>0.051</td>\n      <td>0.125</td>\n      <td>0.023</td>\n      <td>0.026</td>\n      <td>-0.020</td>\n      <td>-0.042</td>\n      <td>0.052</td>\n    </tr>\n    <tr>\n      <th>sms3</th>\n      <td>0.329</td>\n      <td>-0.033</td>\n      <td>-0.035</td>\n      <td>-0.016</td>\n      <td>0.052</td>\n      <td>0.056</td>\n      <td>-0.166</td>\n      <td>-0.074</td>\n      <td>0.063</td>\n      <td>-0.108</td>\n      <td>0.022</td>\n      <td>0.023</td>\n      <td>0.073</td>\n      <td>-0.046</td>\n      <td>0.022</td>\n      <td>-0.070</td>\n    </tr>\n    <tr>\n      <th>sms4</th>\n      <td>0.002</td>\n      <td>0.031</td>\n      <td>0.038</td>\n      <td>0.034</td>\n      <td>-0.075</td>\n      <td>-0.093</td>\n      <td>-0.044</td>\n      <td>0.061</td>\n      <td>-0.045</td>\n      <td>0.029</td>\n      <td>0.028</td>\n      <td>-0.009</td>\n      <td>0.027</td>\n      <td>0.034</td>\n      <td>-0.083</td>\n      <td>-0.021</td>\n    </tr>\n    <tr>\n      <th>sms5!</th>\n      <td>-0.016</td>\n      <td>0.059</td>\n      <td>0.014</td>\n      <td>-0.006</td>\n      <td>0.122</td>\n      <td>-0.040</td>\n      <td>0.005</td>\n      <td>0.167</td>\n      <td>-0.023</td>\n      <td>0.064</td>\n      <td>0.041</td>\n      <td>0.055</td>\n      <td>-0.037</td>\n      <td>0.075</td>\n      <td>-0.001</td>\n      <td>0.020</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# try out truncated svd instead\n",
    "svd = TruncatedSVD(n_components=16, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       !  \"  #  #150  #5000  $  %  &  '  (  ...  ü'll  –  —  ‘  ’  “  …  ┾  \\\nsms0   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0   \nsms1   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0   \nsms2!  0  0  0     0      0  0  0  1  1  1  ...     0  0  0  0  0  0  0  0   \nsms3   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0   \nsms4   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0   \n\n       〨ud  鈥  \nsms0     0  0  \nsms1     0  0  \nsms2!    0  0  \nsms3     0  0  \nsms4     0  0  \n\n[5 rows x 9232 columns]\nGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n,            1\n..           1\n...          2\namore        1\navailable    1\nName: sms0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# use LDiA now\n",
    "# start by getting the BOW representation of the sms\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=sms.text).toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(), counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms\n",
    "\n",
    "print(sms.loc['sms0'].text)\n",
    "print(bow_docs.loc['sms0'][bow_docs.loc['sms0'] > 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16, 9232)\n"
     ]
    }
   ],
   "source": [
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "# now we fit that model to our data, which will give us 16 \"topics\" or dimensions\n",
    "ldia = ldia.fit(bow_docs)\n",
    "print(ldia.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n!   20.03   20.44    0.85   52.68    0.06  204.72   36.35  115.52   11.72   \n\"    0.06    9.00    0.06    0.06    0.12    0.06   94.83    2.48    0.06   \n#    0.06    0.06    0.06    0.06    0.06    0.06    0.06    0.06    2.06   \n\n   topic9  topic10  topic11  topic12  topic13  topic14  topic15  \n!   31.97   134.04    38.21   100.30   135.82   481.08     5.19  \n\"   21.29     3.80     0.06     7.41     0.06    92.34    24.30  \n#    0.06     0.06     0.06     0.06     0.06     5.06     0.06  \n"
     ]
    }
   ],
   "source": [
    "components = pd.DataFrame(ldia.components_.T, index=terms, columns=columns)\n",
    "print(components.round(2).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "to      174.492758\nthe     132.447021\nand     103.139835\n.        95.918658\nyour     64.338532\nfrom     62.993171\nfor      59.914714\nof       59.226303\nfree     59.122778\ncall     55.558074\nName: topic3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(components.topic3.sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets compute the topic vectors for all documents\n",
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors, index=index, columns=columns)"
   ]
  }
 ]
}